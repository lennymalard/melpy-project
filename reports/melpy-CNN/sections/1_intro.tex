\begin{multicols}{2}
\tableofcontents
\section{Introduction}
Les réseaux de neurones convolutifs ont été cités pour 
la première fois par Yann LeCun en 1998, dans le papier 
\textit{“Gradient-Based Learning Applied to Document Recognition”} \cite{YannLeCunCNNs}.
Il y met en avant l’apprentissage automatique des motifs présents dans les 
images d’un jeu de données et démontre l’efficacité du modèle dans des tâches
de classification. Cependant, ce n’est qu’en 2012 que cette approche 
gagna en popularité grâce à la victoire d’AlexNet\cite{AlexNet} durant la 
compétition de détection d’images ImageNet. Depuis, les CNNs sont reconnues 
comme des architectures performantes dans le domaine de la Vision par Ordinateur, 
et sont exploités pour de nombreuses tâches telles que la reconnaissance 
faciale, l’estimation de poses ou encore la reconnaissance d’actions 
\cite{ApplicationsOfCNNs}. Il est donc aujourd’hui naturel que les bibliothèques 
de deep learning les proposent, et c’est pourquoi Melpy ne déroge pas à la 
règle, bien que la bibliothèque ne reste qu'un support académique. Nous verrons dans 
ce rapport la théorie derrière les CNNs et les choix 
dans leur implémentation pour des tâches de classification. Nous discuterons 
également des performances de Melpy par rapport à Keras, un framework de 
référence pour la réalisation de modèles de deep learning de haut niveau.
\end{multicols}