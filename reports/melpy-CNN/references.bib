@article{Bowker1985,
  doi = {10.2307/2617706},
  url = {https://doi.org/10.2307/2617706},
  year = {1985},
  publisher = {Oxford University Press ({OUP})},
  volume = {61},
  number = {4},
  pages = {607--618},
  author = {Mike Bowker and Phil Williams},
  title = {Helsinki and West European Security},
  journal = {International Affairs}
}

@article{YannLeCunCNNs,
  author = {Yann LeCun and Leon Bottou and Yoshua Bengio and Patrick Haffner},
  title = {GradientBased Learning Applied to Document
Recognition},
  year = {1998},
  url = {http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf}
}

@conference{ApplicationsOfCNNs,
  author = {Sinisa Mihajlovic and Dragan Vojo Ivetic and Ivana Berković},
  title = {Applications of Convolutional Neural Networks},
  year = {2020},
  url = {https://www.researchgate.net/publication/366578101_Applications_of_Convolutional_Neural_Networks}
}

@article{AlexNet,
  author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  title = {ImageNet Classification with Deep Convolutional
Neural Networks},
  year = {2012}
}

@article{MNIST,
  author = {Léon Bottou and Chhavi Yadav},
  title = {Cold Case: the Lost MNIST Digits},
  year = {2019},
  url = {https://arxiv.org/pdf/1905.10498}
}

@article{GradientDescent,
  author = {Sebastian Ruder},
  title = {An overview of gradient descent optimization
algorithms},
  year = {2017},
  url = {https://arxiv.org/pdf/1609.04747}
}

@article{MaxPoolingImage1,
  journal = {geeksforgeeks.org},
  url = {https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/},
  note = {Image d'exemple de Max Pooling.}
}

@article{MaxPoolingImage2,
  journal = {digitalocean.com},
  url = {https://www.digitalocean.com/community/tutorials/pooling-in-convolutional-neural-networks},
  note = {Image d'exemple de Max Pooling sur une image.}
}

@article{BackwardMaxPooling,
  author = {Mukul Rathi},
  url = {https://mukulrathi.com/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/},
  note = {Image d'exemple de la propagation arrière du Max Pooling.}
}

@article{ExampleVectorizing,
  author = {Tarang Chikhalia},
  journal = {medium.com},
  title = {Why is Vectorization Preferred Over for Loops in Deep Learning?},
  url = {https://medium.com/@tarangchikhalia/why-is-vectorization-preferred-over-for-loops-in-deep-learning-fddb5bd34507}
}

@article{NumPyEfficiency,
  author = {Stéfan van der Walt and Gael Varoquaux and S. Chris Colbert},
  title = {The NumPy array: a structure for efficient
numerical computation},
  year = {2011},
  url = {https://arxiv.org/pdf/1102.1523}
}

@article{im2col,
  author = {Kumar Chellapilla and Sidd Puri and Patrice Simard},
  title = {High Performance Convolutional Neural Networks for
Document Processing},
  year = {2006},
  url = {https://inria.hal.science/inria-00112631/document}
}

@article{im2colImages,
  author = {Ferdinand Mom},
  journal = {hackmd.io},
  url = {https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast#2-Pooling-layer23},
  note = {Images d'illustrations pour la méthode Im2Col.}
}

@article{CIFAR10,
  author = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
  title = {The CIFAR-10 dataset},
  year = {2009},
  url = {https://www.cs.toronto.edu/~kriz/cifar.html}
}

@article{MLP,
  author = {Valentina Emilia Balas and Nikos E Mastorakis},
  title = {Multilayer perceptron and neural networks},
  url = {https://www.researchgate.net/publication/228340819_Multilayer_perceptron_and_neural_networks},
  year = {2009}
}

@article{autodiff,
  author = {Atilim Gunes Baydin and Barak A. Pearlmutter and Alexey Andreyevich Radul and Jeffrey Mark Siskind},
  url = {https://arxiv.org/pdf/1502.05767},
  title = {Automatic differentiation in machine learning: a survey},
  year = {2015}
}